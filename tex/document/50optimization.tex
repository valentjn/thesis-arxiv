\setdictum{%
  Premature optimization is the root of all evil.%
}{%
  Donald E.\ Knuth \cite{Knuth74Structured}%
}

\longchapter{%
  Gradient-Based Optimization with B-Splines on Sparse Grids%
}{%
  Gradient-Based Optimization with B-Splines on Sparse Grids%
}{%
  Gradient-Based Optimization%
}
\label{chap:50optimization}

\initial{0em}{I}{n this chapter,}
we apply the hierarchical B-spline bases derived in
\cref{chap:30BSplines,chap:40algorithms} to optimization,
which is a major task in simulation technology,
for instance in inverse problems (see \cref{chap:10introduction}).
We pursue a three-step surrogate-based optimization approach:
First, we sample the objective function at specific sparse grid points
to retrieve objective function values.
Second, by interpolating these values with hierarchical bases,
we obtain a surrogate for the objective function.
Third and finally, we discard the original objective function and apply
already existing optimization methods to the surrogate.

\vspace*{\fill}

One of the key advantages of hierarchical B-splines
over common hierarchical bases for
sparse grids is their continuous differentiability.
The derivatives of B-spline surrogates on sparse grids are not only continuous,
but also explicitly known, and they can be evaluated fast.
This gives the opportunity to employ gradient-based optimization methods,
which usually converge significantly faster than gradient-free alternatives.

\vspace*{\fill}

The outline of this chapter is as follows:
We start in \cref{sec:51algorithms}
with a compact overview of textbook optimization algorithms,
\pagebreak%
which comprises gradient-free and gradient-based optimization algorithms
for unconstrained problems as well as algorithms for constrained problems.
In \cref{sec:52method}, we present the main method that
conflates the various optimization algorithms and
the generation of spatially adaptive sparse grids with the
Novak--Ritter criterion to create a single method for the
optimization of sparse grid surrogates.
\Cref{sec:53testProblems} continues with a small array of test problems
for unconstrained and constrained optimization.
In \cref{sec:54results}, we apply the presented method
to the test problems, studying the influence of the different
hierarchical B-splines on optimality gaps and conducting
numerical experiments.
Finally, in \cref{sec:55fuzzy}, we examine the fuzzy extension principle
as an example application of the optimization of
hierarchical B-spline surrogates on sparse grids.

Parts of this chapter have already been published in previous work
\cite{Valentin14Hierarchische}, especially
the overview of optimization algorithms (\cref{sec:51algorithms})
and the methodology of the optimization of sparse grid surrogates
(\cref{sec:52method}).
However, as the previous work included other basis functions as well,
this chapter represents the first comprehensive study
that focuses on the application of hierarchical B-splines to optimization.

\input{document/51algorithms}
\input{document/52method}
\input{document/53testProblems}
\input{document/54results}
\input{document/55fuzzy}

\cleardoublepage
